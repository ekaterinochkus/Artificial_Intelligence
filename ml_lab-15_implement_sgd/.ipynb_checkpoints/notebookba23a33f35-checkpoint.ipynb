{"metadata":{"anaconda-cloud":{},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<center>\n<img src=\"https://habrastorage.org/files/fd4/502/43d/fd450243dd604b81b9713213a247aa20.jpg\" />\n    \n## [mlcourse.ai](https://mlcourse.ai) – Open Machine Learning Course \n\nAuthor: [Yury Kashnitskiy](https://yorko.github.io). Translated by [Sergey Oreshkov](https://www.linkedin.com/in/sergeoreshkov/). This material is subject to the terms and conditions of the [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license. Free use is permitted for any non-commercial purpose.","metadata":{"_uuid":"a319e96cc5bb401301e969fe4d4c7cff9a28c0d8"}},{"cell_type":"markdown","source":"# <center> Assignment #8 (demo). Solution\n\n## <center> Implementation of online regressor","metadata":{"_uuid":"1cdf0882b12343dbc386bcfdc8d4b0fc80bde23f"}},{"cell_type":"markdown","source":"Here we'll implement a regressor trained with stochastic gradient descent (SGD). Fill in the missing code. If you do evething right, you'll pass a simple embedded test.","metadata":{"_uuid":"52ae01579348990b5eb4a0be8dec2eba90ca7817"}},{"cell_type":"markdown","source":"## <center>Linear regression and Stochastic Gradient Descent","metadata":{"_uuid":"53ae5da94e33bb916f98ad225bc7d19bc57a71de"}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom tqdm import tqdm\nfrom sklearn.base import BaseEstimator\nfrom sklearn.metrics import mean_squared_error, log_loss, roc_auc_score\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler","metadata":{"_uuid":"334073c26376cdea172693a3931be834cbfa1e32","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Implement class `SGDRegressor`. Specification:\n- class is inherited from `sklearn.base.BaseEstimator`\n- constructor takes parameters `eta` – gradient step ($10^{-3}$ by default) and `n_epochs` – dataset pass count (3 by default)\n- constructor also creates `mse_` and `weights_` lists in order to track mean squared error and weight vector during gradient descent iterations\n- Class has `fit` and `predict` methods\n- The `fit` method takes matrix `X` and vector `y` (`numpy.array` objects) as parameters, appends column of ones to  `X` on the left side, initializes weight vector `w` with **zeros** and then makes `n_epochs` iterations of weight updates (you may refer to this [article](https://medium.com/open-machine-learning-course/open-machine-learning-course-topic-8-vowpal-wabbit-fast-learning-with-gigabytes-of-data-60f750086237) for details), and for every iteration logs mean squared error and weight vector `w` in corresponding lists we created in the constructor. \n- Additionally the `fit` method will create `w_` variable to store weights which produce minimal mean squared error\n- The `fit` method returns current instance of the `SGDRegressor` class, i.e. `self`\n- The `predict` method takes `X` matrix, adds column of ones to the left side and returns prediction vector, using weight vector `w_`, created by the `fit` method.","metadata":{"_uuid":"29d38d8064dc7d282bd1cb4764db79ed4f9b86a2"}},{"cell_type":"code","source":"class SGDRegressor(BaseEstimator):\n    \n    def __init__(self, eta=1e-3, n_epochs=3):\n        self.eta = eta\n        self.n_epochs = n_epochs\n        self.mse_ = []\n        self.weights_ = []\n        \n    def fit(self, X, y):\n        # add a column of ones to the left from X\n        X = np.hstack([np.ones([X.shape[0], 1]), X])\n        \n        # initialize w with zeros, (d + 1)-dimensional (2-dimensional)\n        w = np.zeros(X.shape[1])\n        \n        for it in tqdm(range(self.n_epochs)):\n            for i in range(X.shape[0]):\n                \n                # new_w is used for simultanious updates of w_0, w_1, ..., w_d\n                new_w = w.copy()\n                # special (simpler) formula for w_0\n                new_w[0] += self.eta * (y[i] - w.dot(X[i, :]))\n                for j in range(1, X.shape[1]):\n                    new_w[j] += self.eta * (y[i] - w.dot(X[i, :])) * X[i, j]  \n                w = new_w.copy()\n                \n                # store the current weight vector\n                self.weights_.append(w)\n                # store current loss function\n                self.mse_.append(mean_squared_error(y, X.dot(w)))\n        # the \"best\" vector of weights        \n        self.w_ = self.weights_[np.argmin(self.mse_)]\n                \n        return self\n                  \n    def predict(self, X):\n        # add a column of ones to the left from X\n        X = np.hstack([np.ones([X.shape[0], 1]), X])\n        # linear prediction\n        return X.dot(self.w_)                  ","metadata":{"_uuid":"a186296efd87e4ddea57c722991e235597c38695","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Let's test out the algorithm on height/weight data. We will predict heights (in inches) based on weights (in lbs).","metadata":{"_uuid":"c0d81657534244bf31f801c5fc7703af3690c52e"}},{"cell_type":"code","source":"data_demo = pd.read_csv('../input/weights_heights.csv')","metadata":{"_uuid":"075da927a504971d1d360081565f1ac38a93b505","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.scatter(data_demo['Weight'], data_demo['Height']);\nplt.xlabel('Weight (lbs)')\nplt.ylabel('Height (Inch)')\nplt.grid();","metadata":{"_uuid":"ac981530806ecc1711a42ddf45318d5b125e843c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X, y = data_demo['Weight'].values, data_demo['Height'].values","metadata":{"_uuid":"c4ec658cd830c6d30bd924af56c50042f48cdca2","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Perform train/test split and scale data.","metadata":{"_uuid":"8ccede2e7d8d37eb0f291cd4a92e22946b29c45d"}},{"cell_type":"code","source":"X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n                                                     test_size=0.3,\n                                                     random_state=17)","metadata":{"_uuid":"c4e35be8ea1561f2b2785647a304800f2402b491","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"scaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train.reshape([-1, 1]))\nX_valid_scaled = scaler.transform(X_valid.reshape([-1, 1]))","metadata":{"_uuid":"b81ce120053c64834775f97dfb9c43b7f2d293de","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train created `SGDRegressor` with `(X_train_scaled, y_train)` data. Leave default parameter values for now.","metadata":{"_uuid":"78d995d43a80b313d702b9e8a48fd9a9f12e91d2"}},{"cell_type":"code","source":"# you code here\nsgd_reg = SGDRegressor()\nsgd_reg.fit(X_train_scaled, y_train)","metadata":{"_uuid":"a04e1946a6b1d5e2c12c1e26e2777b038f955924","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Draw a chart with training process  – dependency of mean squared error from the i-th SGD iteration number.","metadata":{"_uuid":"2bd722f2e5be1179e31c2e7776da079edc33fcab"}},{"cell_type":"code","source":"# you code here\nplt.plot(range(len(sgd_reg.mse_)), sgd_reg.mse_)\nplt.xlabel('#updates')\nplt.ylabel('MSE');","metadata":{"_uuid":"886fe93cf3fcd71dc48b9b1c2dad3d7029b9011c","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Print the minimal value of mean squared error and the best weights vector.","metadata":{"_uuid":"c7bfc0d873a4be226070621b6c7331468b153307"}},{"cell_type":"code","source":"# you code here\nnp.min(sgd_reg.mse_), sgd_reg.w_","metadata":{"_uuid":"ff0acf573cdfc9bceaa0c7da5d9956fc78c5442b","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Draw chart of model weights ($w_0$ and $w_1$) behavior during training.","metadata":{"_uuid":"9dc62e410ab9fa047bab3d9adbe46adfd02afb5a"}},{"cell_type":"code","source":"# you code here\nplt.subplot(121)\nplt.plot(range(len(sgd_reg.weights_)), \n         [w[0] for w in sgd_reg.weights_]);\nplt.subplot(122)\nplt.plot(range(len(sgd_reg.weights_)), \n         [w[1] for w in sgd_reg.weights_]);","metadata":{"_uuid":"cd618e5d6c9a957663ac6a48d6b00f4a3309a70d","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Make a prediction for hold-out  set `(X_valid_scaled, y_valid)` and check MSE value.","metadata":{"_uuid":"891e209c91164b8504b3b739c7677b4e495e877d"}},{"cell_type":"code","source":"# you code here\nsgd_holdout_mse = mean_squared_error(y_valid, \n                                        sgd_reg.predict(X_valid_scaled))\nsgd_holdout_mse","metadata":{"_uuid":"8a60f50f83725b8042399e8736d2063f8952ae86","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Do the same thing for `LinearRegression` class from `sklearn.linear_model`. Evaluate MSE for hold-out set.","metadata":{"_uuid":"c6e7255ca6576f5a2fa5200ab70b7bfaac691303"}},{"cell_type":"code","source":"# you code here\nfrom sklearn.linear_model import LinearRegression\nlm = LinearRegression().fit(X_train_scaled, y_train)\nprint(lm.coef_, lm.intercept_)\nlinreg_holdout_mse = mean_squared_error(y_valid, \n                                        lm.predict(X_valid_scaled))\nlinreg_holdout_mse","metadata":{"scrolled":true,"_uuid":"a81830ceba9748ec004f8dfa9104bf318fd88f57","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    assert (sgd_holdout_mse - linreg_holdout_mse) < 1e-4\n    print('Correct!')\nexcept AssertionError:\n    print(\"Something's not good.\\n Linreg's holdout MSE: {}\"\n          \"\\n SGD's holdout MSE: {}\".format(linreg_holdout_mse, \n                                            sgd_holdout_mse))","metadata":{"_uuid":"5a1b2eb42c6cbdb196d83ac9787978ef95a9cb5d","trusted":true},"execution_count":null,"outputs":[]}]}